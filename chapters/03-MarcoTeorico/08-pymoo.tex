\section[AGs Simples mediante \texttt{pymoo}]{Algoritmos Genéticos (AGs) Simples Mono-objetivo mediante \texttt{pymoo}}

\subsection{Introducción a los Algoritmos Genéticos (AGs) Simples}
La optimización, como disciplina fundamental, se dedica a la búsqueda de la mejor solución posible para un problema dado, considerando las restricciones existentes. Su importancia se manifiesta en una amplia gama de campos, desde la ingeniería y la ciencia hasta la economía y la inteligencia artificial, donde la necesidad de encontrar soluciones eficientes y efectivas es primordial. Dentro del vasto panorama de las técnicas de optimización, la computación evolutiva emerge como un paradigma de resolución de problemas inspirado en los mecanismos de la evolución natural~\cite{eiben2015}. Los Algoritmos Genéticos (AGs) constituyen una clase prominente de algoritmos evolutivos que han demostrado su eficacia en la resolución de problemas de optimización complejos~\cite{goldberg1989}.

La idea central detrás de los AGs radica en la simulación de los principios de la selección natural, la recombinación genética (cruce) y la mutación para mejorar iterativamente una población de soluciones candidatas~\cite{goldberg1989}. De manera análoga a la evolución biológica, donde los individuos mejor adaptados tienen una mayor probabilidad de sobrevivir y reproducirse, los AGs evalúan la ``aptitud'' de cada solución candidata mediante una función objetivo. Las soluciones más aptas tienen una mayor probabilidad de ser seleccionadas para producir la siguiente generación, combinando su información genética a través del cruce y sufriendo mutaciones aleatorias. Este proceso iterativo, que se repite a lo largo de varias generaciones, busca converger hacia una solución óptima para el problema planteado. El presente informe se centra específicamente en la implementación canónica de AGs simples diseñados para abordar problemas de optimización con un único objetivo dentro del contexto de la biblioteca Pymoo~\cite{blank2020}.

Los AGs resultan particularmente útiles para problemas de optimización mono-objetivo que presentan características desafiantes para los métodos tradicionales basados en gradientes. Su capacidad para explorar espacios de búsqueda complejos, no lineales y no diferenciables los convierte en una herramienta valiosa en escenarios donde la función objetivo exhibe múltiples óptimos locales o una superficie de búsqueda irregular. A diferencia de los métodos deterministas que siguen una trayectoria específica guiada por el gradiente, los AGs operan sobre una población de soluciones y emplean operadores estocásticos, lo que les permite explorar una gama más amplia de posibles soluciones y ser más robustos frente a quedar atrapados en óptimos locales. Esta característica fundamental motiva su aplicación en una variedad de problemas del mundo real donde la complejidad de la función objetivo dificulta el uso de técnicas convencionales.

El término ``canónico'' alude a una forma estándar o ampliamente aceptada del AG simple~\cite{goldberg1989}. Esta forma fundamental típicamente involucra la representación binaria de las soluciones candidatas, un mecanismo de selección proporcional a la aptitud (como la ruleta), un operador de cruce de un solo punto y un operador de mutación de inversión de bits. Si bien la biblioteca Pymoo puede ofrecer una mayor flexibilidad y una variedad de operadores más avanzados~\cite{blank2020}, comprender esta estructura básica es esencial para contextualizar la implementación específica que se analizará en este informe. Establecer esta base desde el principio permitirá al lector comprender mejor cómo la implementación de Pymoo se alinea con los principios fundamentales de un AG canónico y cómo potencialmente los extiende o adapta.

\subsection{Descripción General de la Biblioteca Pymoo}

Pymoo se presenta como una biblioteca moderna y rica en funcionalidades, escrita en Python y diseñada principalmente para abordar problemas de optimización multiobjetivo~\cite{blank2020}. No obstante, su arquitectura versátil y su diseño modular la convierten también en una herramienta poderosa para la resolución de problemas de optimización con un único objetivo. Una de sus principales fortalezas reside en su capacidad para separar claramente los componentes de un problema de optimización (la función objetivo, las variables de decisión y las restricciones) de los algoritmos de optimización propiamente dichos y de los operadores genéticos utilizados. Esta separación promueve la flexibilidad y la reutilización del código, permitiendo a los usuarios experimentar fácilmente con diferentes combinaciones de algoritmos y operadores para un mismo problema.

La biblioteca Pymoo destaca por su amplio soporte para una variedad de algoritmos de optimización, que abarcan tanto técnicas evolutivas, como los Algoritmos Genéticos, la Optimización por Enjambre de Partículas y la Evolución Diferencial, como también métodos clásicos de optimización~\cite{blank2020}. Además, proporciona un conjunto completo de herramientas para la definición de problemas de optimización, la implementación de operadores genéticos personalizados y la evaluación del rendimiento de los algoritmos. Su extensibilidad es otra característica clave, ya que permite a los usuarios implementar fácilmente sus propios algoritmos, operadores o criterios de terminación si las opciones predefinidas no se ajustan a sus necesidades específicas.

Aunque el enfoque principal de Pymoo radica en la optimización multiobjetivo~\cite{Deb2005, blank2020}, su marco de trabajo subyacente y muchos de sus operadores pueden aplicarse directamente o tienen contrapartidas específicas para el caso de la optimización con un solo objetivo. Esto significa que los usuarios interesados en resolver problemas con una única función objetivo pueden beneficiarse igualmente de la robustez y la flexibilidad que ofrece la biblioteca. La arquitectura de Pymoo se organiza en varios módulos clave que interactúan para definir y ejecutar los procesos de optimización. Estos módulos incluyen:
\begin{itemize}
    \item \texttt{\seqsplit{pymoo.core.problem}}: Este módulo proporciona las clases base para definir problemas de optimización, especificando la función objetivo, el número y los límites de las variables de decisión, así como cualquier restricción que deba cumplirse.
    \item \texttt{\seqsplit{pymoo.algorithms}}: Contiene implementaciones de una amplia gama de algoritmos de optimización, incluyendo la clase GA para problemas mono-objetivo que será el foco de este informe.
    \item \texttt{\seqsplit{pymoo.operators}}: Ofrece una colección diversa de operadores genéticos esenciales para los algoritmos evolutivos, como operadores de selección (para elegir los padres), operadores de cruce (para combinar la información genética) y operadores de mutación (para introducir variaciones aleatorias).
    \item \texttt{\seqsplit{pymoo.termination}}: Define diferentes criterios que pueden utilizarse para detener el proceso de optimización, como alcanzar un número máximo de generaciones o un cierto nivel de convergencia.
    \item \texttt{\seqsplit{pymoo.optimize}}: Proporciona funciones de alto nivel para facilitar la ejecución de los algoritmos de optimización una vez que se han definido el problema y el algoritmo deseado.
\end{itemize}

La filosofía de diseño de Pymoo, que separa claramente la definición del problema, la implementación del algoritmo y la aplicación de los operadores, promueve una flexibilidad y una capacidad de reutilización significativas~\cite{blank2020}. Esto implica que un mismo problema de optimización podría potencialmente resolverse utilizando diferentes algoritmos mono-objetivo disponibles en Pymoo, lo que facilita la realización de estudios comparativos de rendimiento. Esta capacidad de desacoplamiento permite a los usuarios experimentar con diversas combinaciones de algoritmos y operadores sin necesidad de reescribir la definición del problema cada vez, lo que representa una ventaja considerable tanto para la investigación como para las aplicaciones prácticas.

\subsection{El Algoritmo Genético Canónico en Pymoo}

Pymoo proporciona una implementación fácilmente accesible de un Algoritmo Genético mono-objetivo que se alinea de cerca con la forma canónica descrita anteriormente~\cite{goldberg1989}. Dentro de la biblioteca, la clase \texttt{\seqsplit{pymoo.algorithms.soo.nonconvex.ga.GA}}, ubicada en el módulo \texttt{\seqsplit{pymoo.algorithms.soo.nonconvex}}, constituye el foco principal para la discusión de la implementación canónica de un AG mono-objetivo~\cite{blank2020}. La designación \texttt{\seqsplit{soo}} en el nombre del módulo indica que se trata de un algoritmo diseñado para la Optimización con un Solo Objetivo, mientras que \texttt{\seqsplit{nonconvex}} sugiere que es adecuado para problemas donde la función objetivo puede no ser convexa, una característica común en los escenarios donde los AGs suelen ser efectivos.

Si bien Pymoo ofrece una variedad de otros algoritmos de optimización mono-objetivo, la clase \texttt{\seqsplit{GA}} se destaca como una representación directa de un AG estándar, incorporando los componentes fundamentales y el flujo de trabajo típico de este tipo de algoritmo evolutivo. El proceso general para utilizar la clase \texttt{\seqsplit{GA}} en Pymoo sigue una serie de pasos bien definidos:
\begin{itemize}
    \item \textbf{Definición del Problema de Optimización:} El primer paso crucial consiste en definir el problema específico que se desea resolver. Esto se realiza mediante la creación de una instancia de la clase \texttt{\seqsplit{Problem}} de Pymoo (o una de sus subclases), donde se especifica la función objetivo que se va a minimizar o maximizar, el número de variables de decisión involucradas y los límites inferior y superior para cada una de estas variables. Adicionalmente, si el problema incluye alguna restricción que las soluciones deben satisfacer, estas también se definen en este paso.
    \item \textbf{Creación de una Instancia del Algoritmo Genético:} Una vez definido el problema, se procede a crear una instancia de la clase \texttt{\seqsplit{GA}}. Durante esta instanciación, se deben especificar varios parámetros que controlan el comportamiento del algoritmo, como el tamaño de la población (\texttt{\seqsplit{pop\_size}}), el método de muestreo para generar la población inicial (\texttt{\seqsplit{sampling}}), el operador de cruce (\texttt{\seqsplit{crossover}}) que se utilizará para combinar la información genética de los padres y el operador de mutación (\texttt{\seqsplit{mutation}}) que se aplicará para introducir variaciones aleatorias en la descendencia.
    \item \textbf{Ejecución del Algoritmo:} Con el problema definido y el algoritmo instanciado y configurado, el siguiente paso es ejecutar el proceso de optimización. Esto se logra llamando al método \texttt{\seqsplit{solve~()}} de la instancia de la clase \texttt{\seqsplit{GA}}, pasando como argumento el objeto que representa el problema de optimización definido en el paso anterior.
    \item \textbf{Análisis de los Resultados:} Una vez que el algoritmo ha terminado de ejecutarse (ya sea por alcanzar un criterio de terminación predefinido o por completarse el número máximo de generaciones), el método \texttt{\seqsplit{solve~()}} devuelve un objeto de tipo \texttt{\seqsplit{Result}} que contiene información relevante sobre la ejecución de la optimización. Esta información típicamente incluye la mejor solución encontrada (los valores de las variables de decisión que producen el mejor valor de la función objetivo) y el valor correspondiente de la función objetivo.
\end{itemize}

Es importante señalar que, si bien la clase \texttt{\seqsplit{pymoo.algorithms.soo.nonconvex.ga.GA}} es una representación fundamental de un AG canónico dentro de Pymoo~\cite{blank2020}, la flexibilidad de la biblioteca podría permitir la existencia de otras implementaciones o variantes de AGs, ya sea dentro de la propia biblioteca o aportadas por la comunidad de usuarios. No obstante, para los fines de este informe y con el objetivo de proporcionar una comprensión clara de la forma ``canónica'', nos centraremos en el análisis detallado de esta clase específica debido a su estrecha correspondencia con la estructura tradicional de un AG~\cite{goldberg1989}.

\subsection{Análisis Detallado de la Clase \texttt{\url{pymoo.algorithms.soo.nonconvex.ga.GA}}}

La clase \texttt{\seqsplit{pymoo.algorithms.soo.nonconvex.ga.GA}} se configura principalmente a través de su constructor, que acepta varios parámetros clave que definen el comportamiento del algoritmo genético. Estos parámetros permiten a los usuarios adaptar el algoritmo a las características específicas del problema que se está abordando. A continuación, se presenta un análisis detallado de los parámetros más importantes del constructor:
\begin{itemize}
    \item \texttt{\seqsplit{pop\_size}}: Este parámetro de tipo entero especifica el número de individuos que conformarán la población en cada generación del algoritmo. El tamaño de la población influye significativamente en el rendimiento del AG.\ Una población más grande permite una mayor exploración del espacio de búsqueda, lo que puede aumentar la probabilidad de encontrar la solución óptima, pero también incrementa el costo computacional. Por otro lado, una población más pequeña puede converger más rápidamente, pero corre el riesgo de quedar atrapada en óptimos locales. La elección del tamaño de la población suele ser un compromiso que depende de la complejidad del problema y los recursos computacionales disponibles.
    \item \texttt{\seqsplit{sampling}}: Este parámetro define el método que se utilizará para crear la población inicial de individuos. Acepta un objeto de una clase de muestreo proporcionada por Pymoo (generalmente del módulo \texttt{\seqsplit{pymoo.operators.sampling}}). Una opción común es \texttt{\seqsplit{RandomSampling}}, que genera individuos con valores de variables de decisión distribuidos uniformemente dentro de sus respectivos límites. La estrategia de muestreo inicial puede tener un impacto considerable en la diversidad inicial de la población, lo que a su vez puede afectar la capacidad del algoritmo para explorar eficazmente el espacio de búsqueda.
    \item \texttt{\seqsplit{crossover}}: Este parámetro especifica el operador de cruce que se aplicará durante el proceso de reproducción. Acepta un objeto de una clase de operador de cruce del módulo \texttt{\seqsplit{pymoo.operators.crossover}}. Pymoo ofrece una variedad de operadores de cruce diseñados para diferentes tipos de representación de variables de decisión. Por ejemplo, para problemas con variables continuas, un operador común es \texttt{\seqsplit{SBX}} (Simulated Binary Crossover)~\cite{deb1995}, mientras que para problemas con variables binarias se podrían utilizar operadores como \texttt{\seqsplit{SinglePointCrossover}} o \texttt{\seqsplit{TwoPointCrossover}}. La elección del operador de cruce influye en cómo se combina la información genética de los padres para generar nuevos descendientes.
    \item \texttt{\seqsplit{mutation}}: De manera similar al parámetro \texttt{\seqsplit{crossover}}, este parámetro define el operador de mutación que se utilizará para introducir variaciones aleatorias en la población. Acepta un objeto de una clase de operador de mutación del módulo \texttt{\seqsplit{pymoo.operators.mutation}}. Al igual que con el cruce, Pymoo proporciona varios operadores de mutación adecuados para diferentes tipos de variables. Por ejemplo, \texttt{\seqsplit{PolynomialMutation}} se utiliza a menudo para variables continuas~\cite{deb1996}, mientras que \texttt{\seqsplit{BitflipMutation}} es común para variables binarias. El operador de mutación juega un papel crucial en el mantenimiento de la diversidad genética y en la prevención de la convergencia prematura del algoritmo.
    \item \texttt{\seqsplit{eliminate\_duplicates}}: Este parámetro booleano indica si se deben eliminar los individuos duplicados de la población después de cada generación. Si se establece en \texttt{\seqsplit{True}}, el algoritmo verificará si existen individuos idénticos en la nueva población y los eliminará, manteniendo así una mayor diversidad genética. Si se establece en \texttt{\seqsplit{False}}, se permitirán los duplicados. La eliminación de duplicados puede ayudar a prevenir la convergencia prematura, pero también puede añadir una sobrecarga computacional al proceso.
\end{itemize}

La principal funcionalidad de la clase \texttt{\seqsplit{GA}} se expone a través de sus métodos, siendo el más importante de ellos el método \texttt{\seqsplit{solve~()}}. Este método es el encargado de ejecutar el algoritmo genético y llevar a cabo el proceso iterativo de evolución de la población hasta que se cumple algún criterio de terminación. El método \texttt{\seqsplit{solve~()}} requiere como entrada principal un objeto que represente el problema de optimización que se desea resolver. Este objeto debe ser una instancia de una subclase de \texttt{\seqsplit{pymoo.core.problem.Problem}} y debe definir la función objetivo, el número y los límites de las variables de decisión, y cualquier restricción que sea aplicable. La separación entre la definición del problema y la implementación del algoritmo es un aspecto fundamental del diseño de Pymoo, ya que permite una mayor flexibilidad y modularidad en el proceso de optimización~\cite{blank2020}.

Al finalizar su ejecución, el método \texttt{\seqsplit{solve~()}} devuelve un objeto de tipo \texttt{\seqsplit{pymoo.optimize.result.Result}}. Este objeto contiene información valiosa sobre la ejecución del algoritmo, incluyendo el mejor individuo encontrado durante todo el proceso de optimización (accesible a través del atributo \texttt{\seqsplit{X}}) y el valor correspondiente de la función objetivo para ese individuo (accesible a través del atributo \texttt{\seqsplit{F}}). Además de la mejor solución, el objeto \texttt{\seqsplit{Result}} puede contener otra información útil, como el historial de la evolución de la población o métricas de rendimiento del algoritmo.

\subsection{Componentes y Operadores Clave}
\begin{itemize}[label=\textbullet, leftmargin=*]
    \item \textbf{Inicialización:} La primera etapa en la ejecución de un Algoritmo Genético es la creación de la población inicial de soluciones candidatas. En Pymoo, este proceso está determinado por el parámetro \texttt{\seqsplit{sampling}} que se especifica al instanciar la clase \texttt{\seqsplit{GA}}. El método de muestreo elegido define cómo se generan los individuos iniciales en el espacio de búsqueda del problema. Una estrategia común es \texttt{\seqsplit{RandomSampling}}, que genera soluciones distribuidas uniformemente dentro de los límites definidos para cada variable de decisión. Otras estrategias de muestreo, como el muestreo de hipercubo latino (LHS), también podrían estar disponibles en Pymoo y ofrecer diferentes formas de distribuir inicialmente las soluciones en el espacio de búsqueda. La diversidad de la población inicial es un factor crítico que puede influir significativamente en la capacidad del AG para encontrar el óptimo global. Una población inicial bien diversificada aumenta las posibilidades de explorar una región más amplia del espacio de búsqueda y de evitar la convergencia prematura hacia óptimos locales. La elección de una estrategia de muestreo apropiada debe basarse en las características del problema específico que se está abordando.

    \item \textbf{Evaluación:} Una vez que se ha generado la población inicial (y en cada generación subsiguiente), es necesario evaluar la calidad de cada individuo, es decir, qué tan bien resuelve el problema de optimización. En Pymoo, esta evaluación se realiza llamando a la función objetivo definida dentro del objeto \texttt{\seqsplit{Problem}} para cada individuo de la población. El valor resultante de la función objetivo (o valores, en el caso de optimización multiobjetivo, aunque aquí nos centramos en el caso mono-objetivo) representa la aptitud o ``fitness'' de ese individuo. Cuanto mejor sea el valor de la función objetivo (dependiendo de si se busca minimizar o maximizar), mayor será la aptitud del individuo.

    \item \textbf{Selección:} El operador de selección juega un papel fundamental en la evolución de la población al determinar qué individuos de la generación actual se elegirán como padres para producir la siguiente generación. El objetivo de la selección es favorecer a los individuos con mayor aptitud, aumentando así la probabilidad de que sus ``genes'' (es decir, sus características como soluciones) se transmitan a la siguiente generación. Pymoo implementa varios métodos de selección comunes~\cite{goldberg1989, eiben2015}:
    \begin{itemize}[label=\textbullet, leftmargin=*] % Cambiado a \textbullet
        \item \textit{Selección por Torneo:} En este método, se selecciona aleatoriamente un pequeño grupo de individuos (el tamaño del torneo es un parámetro configurable). El individuo con la mejor aptitud dentro de este grupo se elige como padre. Este proceso se repite hasta que se ha seleccionado el número deseado de padres. El tamaño del torneo influye en la presión de selección: un tamaño mayor aumenta la probabilidad de que los individuos más aptos sean seleccionados.
        \item \textit{Selección por Ruleta (Selección Proporcional a la Aptitud):} En este método, a cada individuo se le asigna una probabilidad de ser seleccionado proporcional a su aptitud relativa en la población. Los individuos con mayor aptitud tienen una mayor probabilidad de ser elegidos. Sin embargo, este método puede presentar problemas si hay un individuo excepcionalmente apto en las primeras generaciones, ya que podría dominar el proceso de selección y llevar a una convergencia prematura.
        \item Pymoo podría ofrecer otros métodos de selección, como la selección basada en el rango, donde la probabilidad de selección se basa en el rango de aptitud del individuo en lugar de su valor absoluto. La elección del método de selección y sus parámetros asociados tiene un impacto significativo en la velocidad de convergencia y en el riesgo de convergencia prematura del algoritmo. Una mayor presión de selección puede acelerar la convergencia, pero también puede aumentar el riesgo de quedar atrapado en óptimos locales.
    \end{itemize}

    \item \textbf{Cruce (Recombinación):} El operador de cruce, también conocido como recombinación, es un mecanismo clave en los Algoritmos Genéticos que permite combinar la información genética de dos individuos padres seleccionados para crear nuevos individuos descendientes~\cite{goldberg1989}. El objetivo del cruce es explorar nuevas regiones del espacio de búsqueda mediante la creación de combinaciones de características que podrían no existir en los padres individualmente. Pymoo proporciona una variedad de operadores de cruce, algunos de los cuales son:
    \begin{itemize}[label=\textbullet, leftmargin=*] % Cambiado a \textbullet
        \item \textit{Cruce de un Punto:} Para representaciones binarias o de enteros, se elige aleatoriamente un único punto de cruce. Los segmentos de los cromosomas de los dos padres se intercambian en este punto para producir dos nuevos descendientes.
        \item \textit{Cruce de Dos Puntos:} Similar al cruce de un punto, pero se eligen dos puntos de cruce. El segmento del cromosoma entre estos dos puntos se intercambia entre los dos padres.
        \item \textit{Cruce Binario Simulado (SBX):} Este operador se utiliza comúnmente para problemas con variables continuas~\cite{deb1995}. Simula el comportamiento del cruce de un punto en el espacio de las variables reales, generando descendientes que se encuentran en la vecindad de los padres en el espacio de búsqueda. El \texttt{\seqsplit{SBX}} tiene un parámetro importante, el factor de dispersión, que controla qué tan lejos de los padres pueden estar los descendientes.
        \item Pymoo puede incluir otros operadores de cruce, como el cruce uniforme, donde cada gen (variable) del descendiente se selecciona aleatoriamente de uno de los dos padres. La elección del operador de cruce debe ser compatible con la representación de las soluciones (por ejemplo, binaria, continua) y puede tener un impacto significativo en la capacidad del algoritmo para explorar y explotar el espacio de búsqueda. El operador de cruce y sus parámetros se especifican en Pymoo a través del parámetro \texttt{\seqsplit{crossover}} en el constructor de la clase \texttt{\seqsplit{GA}}.
    \end{itemize}

    \item \textbf{Mutación:} El operador de mutación introduce pequeños cambios aleatorios en los individuos descendientes después del cruce. El propósito de la mutación es mantener la diversidad genética en la población y evitar la convergencia prematura hacia un óptimo local al introducir nuevo material genético que no estaba presente en la población de padres~\cite{goldberg1989, eiben2015}. Pymoo ofrece varios operadores de mutación:
    \begin{itemize}[label=\textbullet, leftmargin=*] % Cambiado a \textbullet
        \item \textit{Mutación por Inversión de Bits:} Este operador se aplica típicamente a representaciones binarias. Para cada bit del cromosoma de un individuo, existe una pequeña probabilidad (la tasa de mutación) de que su valor se invierta (de 0 a 1 o de 1 a 0).
        \item \textit{Mutación Polinomial:} Este operador se utiliza a menudo para problemas con variables continuas~\cite{deb1996}. Perturba el valor de cada variable de decisión en un individuo en función de una distribución polinomial. La magnitud de la perturbación está controlada por parámetros como la tasa de mutación y el índice de distribución.
        \item Pymoo puede proporcionar otros operadores de mutación, como la mutación gaussiana para variables continuas, donde se añade un pequeño valor aleatorio extraído de una distribución gaussiana al valor de la variable. La tasa de mutación es un parámetro crítico. Una tasa demasiado baja podría no introducir suficiente diversidad, mientras que una tasa demasiado alta podría perturbar las buenas soluciones y hacer que la búsqueda sea más aleatoria. El operador de mutación y sus parámetros se especifican en Pymoo mediante el parámetro \texttt{\seqsplit{mutation}} en el constructor de la clase \texttt{\seqsplit{GA}}.
    \end{itemize}

    \item \textbf{Reemplazo:} Después de que se han generado los nuevos individuos descendientes a través de los procesos de selección, cruce y mutación, es necesario determinar cómo se formará la siguiente generación de la población. En un Algoritmo Genético simple, la estrategia de reemplazo más común es reemplazar toda la población de padres por la población de hijos. Sin embargo, Pymoo podría ofrecer opciones para implementar el elitismo, una estrategia donde uno o varios de los mejores individuos de la generación anterior se conservan y se pasan directamente a la siguiente generación, asegurando que las mejores soluciones encontradas hasta el momento no se pierdan. La implementación del elitismo puede mejorar el rendimiento y la fiabilidad del AG al garantizar que el progreso realizado durante la optimización se mantenga.

    \item \textbf{Criterios de Terminación:} Es fundamental definir cuándo debe detenerse el proceso iterativo del Algoritmo Genético. Sin criterios de terminación adecuados, el algoritmo podría ejecutarse indefinidamente. Pymoo proporciona varios criterios de terminación comunes que se pueden utilizar:
    \begin{itemize}[label=\textbullet, leftmargin=*] % Cambiado a \textbullet
        \item \textit{Número Máximo de Generaciones:} El algoritmo se detiene después de que se ha alcanzado un número predefinido de generaciones. Este es un criterio de terminación simple y comúnmente utilizado.
        \item \textit{Número Máximo de Evaluaciones de la Función Objetivo:} El algoritmo se detiene después de que la función objetivo ha sido evaluada un número máximo de veces. Este criterio es útil en problemas donde la evaluación de la función objetivo es computacionalmente costosa.
        \item \textit{Tolerancia en la Convergencia:} El algoritmo se detiene cuando la mejora en el valor de la función objetivo entre generaciones sucesivas es menor que un umbral predefinido durante un cierto número de generaciones. Esto indica que el algoritmo ha convergido a una solución (posiblemente local).
        \item Pymoo puede ofrecer otros criterios de terminación, como un tiempo máximo de ejecución. Los criterios de terminación se suelen especificar al llamar al método \texttt{\seqsplit{solve~()}} de la clase \texttt{\seqsplit{GA}} o mediante el uso de objetos específicos de criterios de terminación del módulo \texttt{\seqsplit{pymoo.termination}}. La elección de los criterios de terminación adecuados es crucial para asegurar que el algoritmo se ejecute durante el tiempo suficiente para encontrar una buena solución sin desperdiciar recursos computacionales.
    \end{itemize}
\end{itemize}

\subsection{Implementación y Uso Práctico}

A continuación, se presenta un ejemplo de código conciso que ilustra cómo utilizar la clase \texttt{\seqsplit{pymoo.algorithms.soo.nonconvex.ga.GA}} de Pymoo para resolver un problema simple de optimización mono-objetivo. Este ejemplo demostrará los pasos esenciales para definir el problema, configurar el algoritmo genético, ejecutar la optimización y analizar los resultados.
\newpage
\begin{listing}[H]
\begin{minted}[linenos, breaklines]{python}
import numpy as np
from pymoo.core.problem import Problem
from pymoo.algorithms.soo.nonconvex.ga import GA
from pymoo.operators.sampling.rnd import RandomSampling
from pymoo.operators.crossover.sbx import SBX
from pymoo.operators.mutation.pm import PolynomialMutation
from pymoo.optimize import minimize

# 1. Definir el problema de optimización
class MyProblem(Problem):
    def __init__(self):
        super().__init__(n_var=2, n_obj=1, n_constr=0, xl=-5, xu=5)

    def _evaluate(self, x, out, *args, **kwargs):
        out["F"] = np.sum(x**2, axis=1)

# 2. Crear una instancia del problema
problem = MyProblem()

# 3. Crear una instancia del algoritmo genético
algorithm = GA(pop_size=20, sampling=RandomSampling(), crossover=SBX(prob=0.9, eta=15), mutation=PolynomialMutation(prob=0.1, eta=20),eliminate_duplicates=True)

# 4. Ejecutar el algoritmo de optimización
res = minimize(problem,algorithm, ("n_gen", 100), verbose=False)

# 5. Analizar los resultados
print("Mejor solución encontrada:", res.X)
print("Valor de la función objetivo para la mejor solución:", res.F)
\end{minted}
\caption{Ejemplo de código Pymoo para optimización mono-objetivo con AG}
\label{lst:pymoo_example}
\end{listing}



En este ejemplo, primero se define un problema de optimización simple (\texttt{\seqsplit{MyProblem}}) donde el objetivo es minimizar la suma de los cuadrados de dos variables de decisión, cada una con límites entre -5 y 5. Luego, se crea una instancia de la clase \texttt{\seqsplit{GA}}, especificando un tamaño de población de 20 individuos, utilizando un muestreo aleatorio para la población inicial, el operador de cruce \texttt{\seqsplit{SBX}}~\cite{deb1995} con una probabilidad de 0.9 y un factor de distribución de 15, el operador de mutación polinomial~\cite{deb1996} con una probabilidad de 0.1 y un factor de distribución de 20, y habilitando la eliminación de duplicados. A continuación, se llama a la función \texttt{\seqsplit{minimize}} de Pymoo, que toma el problema, el algoritmo y un criterio de terminación (en este caso, un máximo de 100 generaciones) como argumentos. Finalmente, se imprimen la mejor solución encontrada (\texttt{\seqsplit{res.X}}) y el valor correspondiente de la función objetivo (\texttt{\seqsplit{res.F}}). Este ejemplo ilustra el flujo de trabajo básico para utilizar el AG canónico en Pymoo~\cite{blank2020}.

\subsubsection{Configuración y Ajuste de Parámetros}

La elección adecuada de los valores para los parámetros del Algoritmo Genético, como el tamaño de la población, la probabilidad de cruce y la probabilidad de mutación, es de suma importancia para lograr un buen rendimiento del algoritmo~\cite{eiben2015}. Estos parámetros influyen directamente en la capacidad del algoritmo para explorar el espacio de búsqueda, explotar las buenas soluciones encontradas y converger hacia un óptimo. No existe un conjunto de parámetros universalmente óptimo que funcione bien para todos los problemas; los mejores valores a menudo dependen de las características específicas del problema que se está resolviendo.

El tamaño de la población (\texttt{\seqsplit{pop\_size}}) determina el número de soluciones candidatas que se mantienen y evolucionan en cada generación. Un tamaño de población mayor permite una exploración más exhaustiva del espacio de búsqueda, lo que puede aumentar la probabilidad de encontrar el óptimo global, especialmente en problemas complejos con muchos óptimos locales. Sin embargo, una población más grande también implica un mayor costo computacional por generación. Por otro lado, un tamaño de población más pequeño puede resultar en una convergencia más rápida, pero corre el riesgo de estancarse en óptimos locales debido a una exploración limitada. Los rangos típicos para el tamaño de la población pueden variar ampliamente, desde unas pocas decenas hasta varios cientos, dependiendo de la complejidad del problema.

La probabilidad de cruce (a menudo un parámetro del operador de cruce, como \texttt{\seqsplit{prob}} en el ejemplo del operador \texttt{\seqsplit{SBX}}) controla la frecuencia con la que se aplica el operador de cruce a los padres seleccionados. Una probabilidad de cruce alta favorece la exploración al generar nuevas soluciones mediante la combinación de la información genética de los padres. Una probabilidad de cruce baja, por otro lado, permite que las soluciones se transmitan a la siguiente generación con menos cambios, lo que puede ser beneficioso en las etapas posteriores de la búsqueda cuando se están afinando las soluciones cercanas al óptimo. Los valores típicos para la probabilidad de cruce suelen estar en el rango de 0.8 a 0.95~\cite{eiben2015}.

La probabilidad o tasa de mutación (a menudo un parámetro del operador de mutación, como \texttt{\seqsplit{prob}} en el ejemplo del operador de mutación polinomial) determina la probabilidad de que cada gen (o variable) en un individuo descendiente se modifique aleatoriamente. La mutación juega un papel crucial en el mantenimiento de la diversidad genética y en la prevención de la convergencia prematura al introducir nuevas características en la población que no estaban presentes en los padres. Una tasa de mutación demasiado baja puede resultar en una falta de exploración de nuevas áreas del espacio de búsqueda, mientras que una tasa demasiado alta puede perturbar las buenas soluciones y hacer que la búsqueda sea esencialmente aleatoria. Los valores típicos para la tasa de mutación suelen ser bajos, a menudo en el rango de 0.01 a 0.1, dependiendo del problema y la representación~\cite{eiben2015}.

Dado que no existen reglas fijas para determinar los valores óptimos de estos parámetros, a menudo es necesario recurrir a la experimentación para encontrar una configuración que funcione bien para un problema específico. Esto puede implicar ejecutar el algoritmo con diferentes combinaciones de parámetros y comparar su rendimiento en términos de la calidad de la solución encontrada y la velocidad de convergencia. Algunas técnicas más avanzadas para el ajuste de parámetros incluyen la búsqueda en cuadrícula (grid search), la búsqueda aleatoria (random search) y métodos de control de parámetros adaptativos, donde los parámetros del algoritmo se ajustan dinámicamente durante el proceso de optimización en función de su rendimiento.

La siguiente tabla (Tabla~\ref{tab:ga_params}) resume los parámetros clave de la clase \texttt{\seqsplit{pymoo.algorithms.soo.nonconvex.ga.GA}} y su impacto en el rendimiento del algoritmo:

\begin{table}[htbp]
\centering
\caption{Parámetros Clave de la Clase \texttt{\url{pymoo.algorithms.soo.nonconvex.ga.GA}}}%
\label{tab:ga_params}
\begin{tabularx}{\textwidth}{@{}l>{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}p{0.2\textwidth}>{\raggedright\arraybackslash}X@{}}
\toprule
\textbf{Parámetro} & \textbf{Descripción} & \textbf{Rango/Valores Típicos} & \textbf{Impacto en el Rendimiento} \\
\midrule
\texttt{\seqsplit{pop\_size}} & Número de individuos en la población. & 50\-500 (según la complejidad) & Valores más altos aumentan la exploración pero también el costo computacional. Valores más bajos pueden llevar a convergencia prematura. \\
\midrule
\texttt{\seqsplit{sampling}} & Método para crear la población inicial. & \texttt{\seqsplit{RandomSampling}}, \texttt{\seqsplit{LHS}} & Influye en la diversidad inicial de la población y la cobertura del espacio de búsqueda. \\
\midrule
\texttt{\seqsplit{crossover}} & Operador de cruce para generar descendencia (ej., \texttt{\seqsplit{SBX}}~\cite{deb1995}, \texttt{\seqsplit{PMX}}). & Depende del problema & Determina cómo se combina la información genética. Diferentes operadores tienen diferentes características de búsqueda. \\
\midrule
\texttt{\seqsplit{mutation}} & Operador de mutación para mantener diversidad (ej., \texttt{\seqsplit{PolynomialMutation}}~\cite{deb1996}). & Depende de la codificación & Introduce cambios aleatorios para mantener la diversidad genética y evitar óptimos locales. \\
\midrule
\texttt{\seqsplit{eliminate\_duplicates}} & Indicador para eliminar individuos duplicados. & \texttt{\seqsplit{True}}, \texttt{\seqsplit{False}} & Ayuda a prevenir convergencia prematura manteniendo diversidad, pero añade costo computacional. \\
\bottomrule
\end{tabularx}
\end{table}

\subsection{Consideraciones Adicionales}

La modularidad de Pymoo facilita la experimentación con diferentes componentes del AG, como los operadores de selección, cruce y mutación, lo que permite a los investigadores y profesionales explorar diversas estrategias evolutivas para encontrar soluciones óptimas. Si bien esta sección del marco teórico se ha centrado en la implementación canónica del AG, es importante destacar que Pymoo ofrece una amplia gama de otros algoritmos de optimización mono-objetivo, como la Evolución Diferencial y la Optimización por Enjambre de Partículas (PSO), que podrían ser explorados como alternativas o complementos al AG.\ Además, para problemas que involucran múltiples objetivos, Pymoo es especialmente potente gracias a su enfoque principal en la optimización multiobjetivo~\cite{Deb2005, blank2020}.

La extensibilidad de Pymoo permite a los usuarios avanzados implementar sus propios operadores genéticos o modificar el comportamiento del algoritmo \texttt{\seqsplit{GA}} existente para satisfacer necesidades específicas. Para aplicaciones del mundo real, es crucial considerar las posibles restricciones que pueden existir en el problema de optimización. Pymoo proporciona mecanismos para manejar restricciones en problemas mono-objetivo utilizando AGs, lo que amplía su aplicabilidad a una gama más amplia de escenarios. Finalmente, es fundamental evaluar el rendimiento del AG utilizando métricas apropiadas, como la velocidad de convergencia, la calidad de la solución obtenida y la robustez del algoritmo frente a diferentes ejecuciones.

Se anima a los usuarios a experimentar con la clase \texttt{\seqsplit{GA}} en Pymoo y a explorar la extensa documentación de la biblioteca~\cite{blank2020} para descubrir características más avanzadas y aplicaciones en diversos dominios de la optimización. La comprensión de los fundamentos del AG canónico proporcionados en este informe sirve como una base sólida para explorar las capacidades más amplias de Pymoo y para abordar una variedad de problemas de optimización complejos.
